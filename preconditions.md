Some thoughts about what I think might turn out to be four preconditions for conscious machines. 

1. **Simulation loops that reflect temporal phenomenon in the real world**. Those loops do not have to run with the same speed as the real-world phenomena, in contrary. Much will be gained by accelerated play of real-world sequences. Most obvious are our limitations. It does seem that we can not consciously accelerate such (re)plays ourselves. We can however "jump" to other parts in our history and replay from there. The jumping process itself does not seem to be obviously regulated by a conscious process either. The most important temporal dynamics in the brain seems not to reside on a individual neuron level, although spike-time dependent plasticity is of course important. No, it naturally is displayed on a more global level, in the form of alpha to gamma rhythms. These are the ones that are related with the state of being awake and undergo large changes when we fall asleep, meditate, or pay attention. Scientists: [Wolpert](http://scholar.google.com/citations?user=YM8BRlUAAAAJ&hl=en)
2. **An unsupervised specialization algorithm**. The brain implements an algorithm that learns to assign modules specific tasks when the need is there. A complex task is subdivided in more elementary ones in a manner that is not predefined by a programmer. This is perhaps the most difficult thing to swallow for a computer scientist, who often makes a living by exactly that: the proper decomposition of a problem into tractable subproblems. An algorithm that would perform such a decomposition in an unsupervised manner would do this kind of meta stuff that was hitherto just his or her domain! There is a problem with specialization though. As soon as something is specialized, how can we still tackle a problem in a general way? Do we only generalize between different specialized submodules or do we preserve some brain area for generalized problem solving? Scientists: [Tishby](http://www.cs.huji.ac.il/~tishby/)
3. **An intrinsic reward system**. Brains seem to have specialized subsystems to come up with rewards that function as mere indicators for possible external rewards. You will get hungry before you starve. You get scared before you are hurt. Very logical of nature to implement such methods. Similar to the specialization algorithm, to have such internal mechanism, one must get evolutionary benefits, also for small organisms. (Although, especially for smaller organisms, there must be a trade-off between the metabolic costs of an intrinsic reward system and its benefits in terms of survival quality). This means that the way we are build, we are hitchhiking on such mechanisms from distant evolutionary pasts. In other words, the way these systems have been build is by an evolutionary algorithm, not by a cognitive algorithm. The research in this direction tries to build an intrinsically curious system, never stopping with exploration, life long learning. Scientists: [Schmidhuber](http://scholar.google.com/citations?user=gLnCTgIAAAAJ&hl=en&oi=sra), [Oudeyer](http://scholar.google.com/citations?user=gCqGj4sAAAAJ&hl=en&oi=sra)
4. **Grounded in a very rich world**. The bandwidth of information going into our system is phenomenal. The number of rods in one eye is over a 100 million. The number of pain receptors is estimated around 200 per square cm, so that is around 4 million per adult. In comparison, we only have around 10,000 taste buds (but then we have around 5 million olfactory receptors). Anyway, there is an enormous quantity of information flowing into our brain each second, each condensed and preprocessed to be as valuable as possible over evolutionary times. Each time we perform some action in the real world, this data stream shifts, expands, and tumbles around, as if we are navigating using disco lights. We have to recover invariants in this unordered stream of information, and the only way to do this is by our quite primitive macro-actions (especially as a baby). Slowly, we encounter regularities and will not be surprised anymore by our own hand touching our knee, or our own hands moving in font of our eyes; we learn to understand and recognize ourselves in the context of this tumultuous world outside. We find out about our identity in all this turmoil and would not be able to do this as an external observer from some virtual world. This is not just some big data analysis, this is real-world, real-time, submerged, big data processing. A conscious machine cannot be a PC on a desk peering through a pinhole of an TCP connection to only our virtual web world. They need and deserve the same quality of data input as we do, they need to be a robot (until our virtual worlds become richer than our real world). Scientists: [Steels](http://scholar.google.com/citations?user=tP0VrwYAAAAJ&hl=en), [Ziemke](http://scholar.google.com/citations?user=GARhoNwAAAAJ&hl=en)

Please, feel free to comment and to direct me to scientists working on these problems as well.
